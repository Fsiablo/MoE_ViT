{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOGUxBIGgwEN8stKNeusLyG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GitOfTheseus/MoE_ViT/blob/main/Moe_ViT_on_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementation and Training of a MoE-ViT**"
      ],
      "metadata": {
        "id": "-Qdik18ExobG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code implements and train a Vision Transformer (ViT) endowed with Sparse Mixture of Expert (MoE) for image classification on the CIFAR10 Dataset."
      ],
      "metadata": {
        "id": "sY4wiHlKxqFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive to save results, figures and checkpoints\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "hzTh_AkxzSfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q transformers datasets triton # installing libraries not included in colab"
      ],
      "metadata": {
        "id": "dqB4DopO2wtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from datasets import Dataset as Ds\n",
        "from triton.language import trans\n",
        "\n",
        "from transformers import ViTImageProcessor\n",
        "from transformers import ViTForImageClassification"
      ],
      "metadata": {
        "id": "1LLhtkV8-QQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting first parameters and variables\n",
        "random_seed = 0\n",
        "torch.manual_seed(random_seed)\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "dataset_name = 'cifar10'\n",
        "model_name = 'MoE_ViT_on_' + dataset_name"
      ],
      "metadata": {
        "id": "lf1MakkvyET-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Design of the Sparse MoE with MLPs"
      ],
      "metadata": {
        "id": "5U6b-7hIAfqN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "me_kC52qxfCR"
      },
      "outputs": [],
      "source": [
        "class SparseMoE(nn.Module):\n",
        "    \"\"\"Custom Class for Sparse MoE with MLP\"\"\"\n",
        "\n",
        "    def __init__(self, dim, hidden_dim, num_experts=32, top_k=2, experts=None):\n",
        "        super(SparseMoE, self).__init__()\n",
        "        self.num_experts = num_experts\n",
        "        self.top_k = top_k\n",
        "        self.dim = dim\n",
        "\n",
        "        # Defining the experts\n",
        "        self.experts = nn.ModuleList([nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, dim)\n",
        "        ) for _ in range(num_experts)])\n",
        "\n",
        "        # Gating network\n",
        "        self.gate = nn.Linear(dim, num_experts)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_len, dim)\n",
        "        batch_size, seq_len, dim = x.shape\n",
        "\n",
        "        # Calculating gating scores and selecting top-k experts\n",
        "        gate_logits = self.gate(x)  # Shape: (batch_size, seq_len, num_experts)\n",
        "        topk_values, topk_indices = torch.topk(gate_logits, self.top_k, dim=-1)  # Get top-k experts\n",
        "\n",
        "        # Normalizing gating values\n",
        "        topk_values = torch.softmax(topk_values, dim=-1)\n",
        "\n",
        "        # Flattening the batch and sequence dimensions for processing\n",
        "        x_flat = x.view(-1, dim)  # Shape: (batch_size * seq_len, dim)\n",
        "        topk_indices_flat = topk_indices.view(-1, self.top_k)  # Shape: (batch_size * seq_len, top_k)\n",
        "        topk_values_flat = topk_values.view(-1, self.top_k)  # Shape: (batch_size * seq_len, top_k)\n",
        "\n",
        "        # Initializing output tensor\n",
        "        output = torch.zeros_like(x_flat)\n",
        "\n",
        "        # Applying each expert and aggregating outputs\n",
        "        for i in range(self.top_k):\n",
        "            expert_idx = topk_indices_flat[:, i]  # Indices of selected experts for each token\n",
        "            expert_weight = topk_values_flat[:, i].unsqueeze(1)  # Gating values for each token\n",
        "\n",
        "            # Gathering expert outputs using advanced indexing\n",
        "            expert_outputs = torch.stack([self.experts[expert_idx[j]](x_flat[j].unsqueeze(0)) for j in range(x_flat.shape[0])], dim=0).squeeze(1)\n",
        "\n",
        "            # Weighted sum of expert outputs\n",
        "            output += expert_outputs * expert_weight\n",
        "\n",
        "        # Reshaping back to (batch_size, seq_len, dim)\n",
        "        output = output.view(batch_size, seq_len, dim)\n",
        "\n",
        "        return output\n",
        "\n",
        "class CustomOutput(nn.Module):\n",
        "    \"\"\"Custom Class instead of output layer when replacing the Linear layer with the MoE\"\"\"\n",
        "    def __init__(self):\n",
        "        super(CustomOutput, self).__init__()\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        # Bypassing transformation, but keeping residual connection\n",
        "        return hidden_states + input_tensor  # Residual connection remains intact\n",
        "\n",
        "\n",
        "def model_creation(num_classes=10):\n",
        "    \"\"\"Function to implement the ViT with MoE\"\"\"\n",
        "\n",
        "    # Loading Google ViT from Hugging Face\n",
        "    model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
        "    print(\"\\ndense model:\", model)\n",
        "\n",
        "    # Replacing Intermediate Linear Layers with Custom Class MoE in the last two transformer block\n",
        "    for n, layer in enumerate(model.vit.encoder.layer[-2:]):\n",
        "\n",
        "        intermediate_size = layer.intermediate.dense.out_features # Get the size of the intermediate layer\n",
        "        hidden_size = intermediate_size // 2\n",
        "        dim = layer.intermediate.dense.weight.shape[1]  # Input size: 768\n",
        "        hidden_dim = layer.intermediate.dense.weight.shape[0]\n",
        "        moe_layer = SparseMoE(dim, hidden_dim, num_experts=8, top_k=2)\n",
        "        layer.intermediate = moe_layer\n",
        "        layer.output = CustomOutput()\n",
        "\n",
        "    # Replacing the output of the ViT with the number of classes of our dataset\n",
        "    model.classifier = torch.nn.Linear(in_features=model.classifier.in_features, out_features=num_classes)\n",
        "\n",
        "    print(\"\\nMoE model:\", model)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class for Custom Preprocessing of the dataset"
      ],
      "metadata": {
        "id": "wOXAJrLUx0KV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    \"\"\"PyTorch Dataset class for customized processing and transformation of inputs\"\"\"\n",
        "\n",
        "    def __init__(self, ds, transform=None, target_transform=None):\n",
        "        self.ds = ds\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.ds[idx]['img']\n",
        "        label = self.ds[idx]['label']\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)\n",
        "\n",
        "        if self.transform:\n",
        "            inputs = self.transform(images=image, return_tensors=\"pt\")\n",
        "            pixel_values = inputs.pixel_values\n",
        "        if self.target_transform:\n",
        "            label = torch.tensor(label).clone().detach()\n",
        "        return inputs.pixel_values, label"
      ],
      "metadata": {
        "id": "khMKdmBcx1v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classes and Functions to Plot and Analyze performance"
      ],
      "metadata": {
        "id": "rKOTflz_x3gP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Class to easily computing and storing the average and current value\n",
        "    class taken from https://github.com/pranoyr/cnn-lstm/blob/7062a1214ca0dbb5ba07d8405f9fbcd133b1575e/utils.py#L52\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count  #\n",
        "\n",
        "def plot_performances(epoch, performances, model_name):\n",
        "    epochs = range(1, epoch + 1)\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1)\n",
        "\n",
        "    # Set the font size for various elements\n",
        "    fontsize = 14  # Adjust this value as needed\n",
        "\n",
        "    # First plot (losses)\n",
        "    ax1.xaxis.set_label_coords(0.1, -0.2)\n",
        "    ax1.plot(np.array(epochs) - 0.5, performances['train_loss'], 'g', label='Training loss')\n",
        "    ax1.plot(np.array(epochs) - 0.5, performances['eval_loss'], 'b', label='Validation loss')\n",
        "    ax1.set_title('Training and Validation loss', fontsize=fontsize)\n",
        "    ax1.set_xlabel('Epochs', fontsize=fontsize)\n",
        "    ax1.set_ylabel('Loss', fontsize=fontsize)\n",
        "    ax1.set_xticks(np.arange(0.5, epoch + 0.5, 1))\n",
        "    ax1.set_xticklabels([str(int(tick)) for tick in range(1, epoch + 1, 1)], fontsize=fontsize)\n",
        "    ax1.legend(fontsize=fontsize)\n",
        "\n",
        "    # Second plot (accuracies)\n",
        "    ax2.plot(np.array(epochs) - 0.5, performances['train_acc'], 'g', label='Training accuracy')\n",
        "    ax2.plot(np.array(epochs) - 0.5, performances['eval_acc'], 'b', label='Validation accuracy')\n",
        "    ax2.set_title('Training and Validation accuracy', fontsize=fontsize)\n",
        "    ax2.set_xlabel('Epochs', fontsize=fontsize)\n",
        "    ax2.set_ylabel('Loss', fontsize=fontsize)\n",
        "    ax2.set_xticks(np.arange(0.5, epoch + 0.5, 1))\n",
        "    ax2.set_xticklabels([str(int(tick)) for tick in range(1, epoch + 1, 1)], fontsize=fontsize)\n",
        "    ax2.set_ylim(max(0, min(min(min(performances['train_acc']), min(performances['eval_acc'])) - 0.05, 1)))\n",
        "    ax2.legend(fontsize=fontsize)\n",
        "\n",
        "    # Adjust layout and save figure\n",
        "    plt.tight_layout()\n",
        "    fig_dir = os.path.join(os.getcwd(), 'figures', model_name + '_training.png')\n",
        "    os.makedirs(os.path.dirname(fig_dir), exist_ok=True)\n",
        "    plt.savefig(fig_dir)\n",
        "    plt.close('all')\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def calculate_performance(confusion_matrix, class_names, model_name):\n",
        "    \"\"\"Function to compute the model's performance on the test set\"\"\"\n",
        "\n",
        "    # Inizializing the confusion matrix\n",
        "    confusion_matrix = confusion_matrix\n",
        "    total_predicted = confusion_matrix.sum(0)\n",
        "    total_actual = confusion_matrix.sum(1)\n",
        "    totals = confusion_matrix.sum(1).sum(0)\n",
        "\n",
        "    df = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names)\n",
        "    df_pred = pd.DataFrame(total_predicted, index=class_names)\n",
        "    df_actual = pd.DataFrame(total_actual, index=class_names)\n",
        "\n",
        "    total_acc = 0\n",
        "    recall = pd.DataFrame(np.zeros(len(class_names)), index=class_names)\n",
        "    precision = pd.DataFrame(np.zeros(len(class_names)), index=class_names)\n",
        "    overall_perf = pd.DataFrame(np.zeros(1), index=['accuracy'])\n",
        "    for name in class_names:\n",
        "        total_acc += df.loc[name, name]\n",
        "        recall.loc[name] = df.loc[name, name] / df_actual.loc[name]\n",
        "        precision.loc[name] = df.loc[name, name] / df_pred.loc[name]\n",
        "\n",
        "    accuracy = total_acc / totals * 100\n",
        "    error_rate = 100 - accuracy\n",
        "    overall_perf.loc['accuracy', 0] = accuracy\n",
        "\n",
        "    performance_test = {'accuracy': accuracy, 'error_rate': error_rate, 'recall': recall,\n",
        "                        'precision': precision, 'overall_acc': overall_perf}\n",
        "\n",
        "    print(f'RESULTS OF TEST {model_name}')\n",
        "    print(\"the accuracy of the model is {} %\".format(performance_test['accuracy']))\n",
        "    print(\"the error rate of the model is {} %\".format(performance_test['error_rate']))\n",
        "    print(\"recall : \\n{}\".format(performance_test['recall']))\n",
        "    print(\"precision : \\n{}\".format(performance_test['precision']))\n",
        "\n",
        "    results_dir = os.path.join('/content/drive/MyDrive/indeep/results', f'results_{model_name}.pkl')\n",
        "    confusion_matrix_dir = os.path.join('/content/drive/MyDrive/indeep/results', f'conf_matrix_{model_name}.pkl')\n",
        "    with open(results_dir, 'wb') as file:\n",
        "        pickle.dump(performance_test, file)\n",
        "    with open(confusion_matrix_dir, 'wb') as file:\n",
        "        pickle.dump(confusion_matrix, file)\n",
        "\n",
        "    return performance_test\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(performance_test, confusion_matrix, class_names):\n",
        "    fig, ([ax1, ax2], [ax3, ax4]) = plt.subplots(nrows=2, ncols=2,\n",
        "                                                 gridspec_kw={'width_ratios': [7, 3], 'height_ratios': [8, 2]})\n",
        "\n",
        "    # plot 1 confusion matrix\n",
        "    im = ax1.imshow(confusion_matrix)  # x axis = real class, y axis = predicted class\n",
        "    ax1.set_xticks(np.arange(len(class_names)))\n",
        "    ax1.set_yticks(np.arange(len(class_names)))\n",
        "    ax1.set_ylabel('Real Class', fontweight='bold', fontsize=9)\n",
        "    ax1.set_xlabel('Predicted Class', fontweight='bold', fontsize=9)\n",
        "\n",
        "    # Position the x-axis label at the top\n",
        "    ax1.xaxis.set_label_coords(.5, 1.15)  # Keep this for label positioning\n",
        "    ax1.xaxis.tick_top()  # Place ticks at the top\n",
        "    ax1.xaxis.set_label_position('top')  # Ensure the label is at the top\n",
        "\n",
        "    # Align the x-tick labels properly; \"right\" aligns the text to the right of the tick\n",
        "    ax1.tick_params(axis='x', which='both', top=True, labeltop=True, labelsize=10, pad=10)  # Adjust padding\n",
        "    ax1.tick_params(axis='y', which='both', labelsize=10)\n",
        "    ax1.set_xticklabels(class_names, rotation=30, ha=\"left\")\n",
        "    ax1.set_yticklabels(class_names, rotation=60, ha=\"right\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    for i in range(len(class_names)):\n",
        "        for j in range(len(class_names)):\n",
        "            text = ax1.text(j, i, int(confusion_matrix[i, j]),\n",
        "                            ha=\"center\", va=\"center\", color=\"w\")\n",
        "    ## plot 2 recall\n",
        "    ax2.set_title(\"Recall\", fontweight ='bold', fontsize=12)\n",
        "    im = ax2.imshow(performance_test['recall'])\n",
        "    for i, c in enumerate(class_names):\n",
        "        text = ax2.text(0, i, str(round(performance_test['recall'].iloc[i][0]*100, 1)), ha=\"center\", va=\"center\", color=\"w\")\n",
        "    ax2.tick_params(top=False, bottom=False, left=False, right=False)\n",
        "    plt.setp(ax2.get_xticklabels(), visible=False)\n",
        "    plt.setp(ax2.get_yticklabels(), visible=False)\n",
        "\n",
        "    ## plot 3 precision\n",
        "    ax3.set_title(\"Precision\", fontweight ='bold', fontsize=12)\n",
        "    im = ax3.imshow(performance_test['precision'].T)\n",
        "    for i, c in enumerate(class_names):\n",
        "        text = ax3.text(i, 0, str(round(performance_test['precision'].iloc[i][0]*100, 1)), ha=\"center\", va=\"center\",\n",
        "                        color=\"w\")\n",
        "    ax3.tick_params(top=False, bottom=False, left=False, right=False)\n",
        "    plt.setp(ax3.get_xticklabels(), visible=False)\n",
        "    plt.setp(ax3.get_yticklabels(), visible=False)\n",
        "\n",
        "    # plot 4 macro average F1-score\n",
        "    ax4.set_title(\"Macro Avg F1-score\", fontweight ='bold', fontsize=12)\n",
        "    f1_scores = 2 * (performance_test['precision'].values * performance_test['recall'].values) / (\n",
        "                performance_test['precision'].values + performance_test['recall'].values)\n",
        "    macro_avg_f1 = f1_scores.mean()\n",
        "    print(macro_avg_f1)\n",
        "    im = ax4.imshow(pd.DataFrame([macro_avg_f1], columns=['Value']))\n",
        "    text = ax4.text(0, 0, str(round(macro_avg_f1*100, 2)), ha=\"center\", va=\"center\",\n",
        "                    color=\"w\")\n",
        "\n",
        "    ax4.tick_params(top=False, bottom=False, left=False, right=False)\n",
        "    plt.setp(ax4.get_xticklabels(), visible=False)\n",
        "    plt.setp(ax4.get_yticklabels(), visible=False)\n",
        "\n",
        "    fig_dir = os.path.join(os.getcwd(), 'figures', 'conf_mtrx.png')\n",
        "    os.makedirs(os.path.dirname(fig_dir), exist_ok=True)\n",
        "    plt.savefig(fig_dir)\n",
        "    plt.show()\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "hSGNvCBYx4up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_loading(dataset):\n",
        "    \"\"\"Function to load, filter, preprocess the dataset and create Dataloader\"\"\"\n",
        "\n",
        "    global batch_size\n",
        "    batch_size = 32\n",
        "\n",
        "    # To train the dataset on CIFAR10\n",
        "    if dataset == 'cifar10':\n",
        "        # Load the dataset from Hugging Face\n",
        "        cifar10_dataset = load_dataset('uoft-cs/cifar10').with_format('torch')\n",
        "        dataset_to_train = cifar10_dataset\n",
        "\n",
        "        global class_names\n",
        "        class_names = cifar10_dataset['train'].features['label'].names\n",
        "        df_total = dataset_to_train['train'].to_pandas()\n",
        "\n",
        "        # for a smaller train set\n",
        "        #df_total = pd.concat([group.sample(frac=0.2) for _, group in df_total.groupby('label')], axis=0).reset_index(drop=True)\n",
        "\n",
        "        df_valid = pd.concat([group.sample(frac=0.2) for _, group in df_total.groupby('label')], axis=0).reset_index(drop=True)\n",
        "        df_train = df_total.loc[~df_total.index.isin(df_valid.index)].reset_index(drop=True)\n",
        "        dataset_to_train['train'] = Ds.from_pandas(df_train, features=dataset_to_train['train'].features).with_format('torch')\n",
        "        dataset_to_train['valid'] = Ds.from_pandas(df_valid, features=dataset_to_train['train'].features).with_format('torch')\n",
        "\n",
        "    # To train the dataset on tiny ImageNet !!! this dataset does not have any test set\n",
        "    elif dataset == 'tiny_imagenet':\n",
        "        # Load the dataset from Hugging Face\n",
        "        tiny_imagenet_dataset = load_dataset('Maysee/tiny-imagenet').with_format('torch')\n",
        "\n",
        "        # Creating a subset of the dataset for faster training\n",
        "        df_train = tiny_imagenet_dataset['train'].to_pandas()\n",
        "        df_train_filtered = pd.concat([group.sample(frac=0.2) for _, group in df_train[df_train['label'] < 20].groupby('label')], axis=0).reset_index(drop=True)\n",
        "        df_valid = tiny_imagenet_dataset['valid'].to_pandas()\n",
        "        df_valid_filtered = pd.concat([group.sample(frac=0.2) for _, group in df_valid[df_valid['label'] < 20].groupby('label')], axis=0).reset_index(drop=True)\n",
        "        filtered_ds_train = Ds.from_pandas(df_train_filtered, features=tiny_imagenet_dataset['train'].features).with_format('torch')\n",
        "        filtered_ds_valid = Ds.from_pandas(df_valid_filtered, features=tiny_imagenet_dataset['valid'].features).with_format('torch')\n",
        "        print(filtered_ds_train)\n",
        "        filtered_dataset = DatasetDict({\n",
        "            'train': filtered_ds_train,\n",
        "            'valid': filtered_ds_valid\n",
        "        })\n",
        "        dataset_to_train = filtered_dataset\n",
        "\n",
        "    # Loading the preprocessing rules directly from the model\n",
        "    processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
        "    # Preprocessing the data\n",
        "    dataset = {x: CustomImageDataset(dataset_to_train[x], transform=processor, target_transform=True) for x in\n",
        "               ['train', 'valid', 'test']}\n",
        "    # Creating the DataLoader for the training\n",
        "    shuffle_ds = {'train': True, 'valid': False, 'test': False}\n",
        "    dataloader = {x: DataLoader(dataset[x], batch_size=batch_size, shuffle=shuffle_ds[x]) for x in ['train', 'valid', 'test']}\n",
        "\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "U0Tma4KgyTey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(dataloader, model):\n",
        "    \"\"\"Function to train the model\"\"\"\n",
        "\n",
        "    # Defining Training Params\n",
        "    num_epochs = 4\n",
        "    learning_rate = 2e-5\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1) # Currently not used for the training because num_epochs = step_size\n",
        "    training_results = {'valid_accuracy': [], 'total_loss': []}\n",
        "    last_loss = 100\n",
        "\n",
        "    # parameters for early stopping (not used in the current training because num_epochs = patience)\n",
        "    patience = 5\n",
        "    trigger_times = 0\n",
        "\n",
        "    performances = {\n",
        "        'best_acc': 0,\n",
        "        'train_acc': [],\n",
        "        'train_loss': [],\n",
        "        'eval_loss': [],\n",
        "        'eval_acc': [],\n",
        "    }\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "\n",
        "        print('\\n')\n",
        "\n",
        "        for phase in ['train', 'valid']:\n",
        "\n",
        "            if phase == 'train':\n",
        "                print(f'Number of batches in train_loader: {len(dataloader[phase])}')\n",
        "                current_batch = dataloader[phase].batch_size\n",
        "                print(f'Batch size: {current_batch}')\n",
        "                print(f'Number of samples in dataset: {len(dataloader[phase].dataset)}')\n",
        "                train_features, train_labels = next(iter(dataloader[phase]))\n",
        "                print(f'Feature batch shape: {train_features.squeeze(1).shape}')  # IF IT STOPS...\n",
        "                print(f'Labels batch shape: {train_labels.shape}')\n",
        "                model.train()\n",
        "            else:\n",
        "                print(f'\\nValidation phase is starting at {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
        "                model.eval()\n",
        "\n",
        "            losses = AverageMeter()\n",
        "            accuracies = AverageMeter()\n",
        "\n",
        "            for batch_idx, batch_data in enumerate(dataloader[phase]):\n",
        "                batch = {'pixel_values': batch_data[0], 'label': batch_data[1]}\n",
        "                images, labels = batch['pixel_values'].squeeze(1).to(device), batch['label'].to(device)\n",
        "                correct, total = 0, 0\n",
        "                if phase == 'train':\n",
        "                    print(f'training status {round((batch_idx+(len(dataloader[phase])*(epoch-1)))/(len(dataloader[phase])*num_epochs)*100, 2)}% --> batch n: {batch_idx + 1} at {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
        "\n",
        "                # Forward pass\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(images).logits\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    # Calculating loss and backpropagate\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    if phase == 'train':\n",
        "                        optimizer.zero_grad()\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                batch_accuracy = torch.sum(predicted == labels) / current_batch\n",
        "                losses.update(loss.item(), current_batch)\n",
        "                accuracies.update(batch_accuracy.item(), current_batch)\n",
        "\n",
        "            print(f'Epoch [{epoch}/{num_epochs}] {phase} set ({len(dataloader[phase].dataset)} samples): Average loss: {losses.avg:.4f}\\tAcc: {accuracies.avg * 100:.4f}%')\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                performances['train_loss'].append(losses.avg)\n",
        "                performances['train_acc'].append(accuracies.avg)\n",
        "            else:\n",
        "                performances['eval_loss'].append(losses.avg)\n",
        "                performances['eval_acc'].append(accuracies.avg)\n",
        "                if accuracies.avg > performances['best_acc']:\n",
        "                    performances['best_acc'] = accuracies.avg\n",
        "\n",
        "        # Plotting Learning curves\n",
        "        plot_performances(epoch, performances, model_name)\n",
        "\n",
        "        # Custom Early Stopping Rule\n",
        "        if losses.avg > last_loss:\n",
        "            trigger_times += 1\n",
        "            print('Trigger Times before patience:', trigger_times)\n",
        "\n",
        "            if trigger_times >= patience:\n",
        "                print(\"Epoch {}\\n\".format(epoch))\n",
        "                print('Early stopping!')\n",
        "\n",
        "                checkpoint_dict = {'epoch': epoch,\n",
        "                              # The current epoch number, which helps resume training from the correct point.\n",
        "                              'state_dict': model.state_dict(),\n",
        "                              # The model's weights (parameters), stored in the state_dict format.\n",
        "                              'optimizer_state_dict': optimizer.state_dict(),\n",
        "                              # The state of the optimizer, including momenta and other parameters.\n",
        "                              'loss_function': criterion,  # The loss function (criterion) used during training.\n",
        "                              'performances': performances,  # Example of additional metadata\n",
        "                              'lr_scheduler_state_dict': scheduler.state_dict(),  # If using a scheduler\n",
        "                              'hyperparameters': {\n",
        "                                  'batch_size': batch_size,\n",
        "                                  'learning_rate': learning_rate\n",
        "                              },\n",
        "                              'random_seed': random_seed,\n",
        "                              'library_versions': {\n",
        "                                  'torch': torch.__version__,\n",
        "                                  'numpy': np.__version__\n",
        "                              }\n",
        "                              }\n",
        "                checkpoint_dir = os.path.join('/content/drive/MyDrive/indeep/checkpoints', f'checkpoint_{model_name}_{num_epochs}_epoch.pth')\n",
        "                print(f'\\nsaving checkpoint in {checkpoint_dir}\\n')\n",
        "                torch.save(checkpoint_dict, checkpoint_dir)\n",
        "\n",
        "                return performances, model\n",
        "\n",
        "\n",
        "        last_loss = losses.avg\n",
        "        checkpoint_dict = {'epoch': epoch,\n",
        "                      # The current epoch number, which helps resume training from the correct point.\n",
        "                      'state_dict': model.state_dict(),\n",
        "                      # The model's weights (parameters), stored in the state_dict format.\n",
        "                      'optimizer_state_dict': optimizer.state_dict(),\n",
        "                      # The state of the optimizer, including momenta and other parameters.\n",
        "                      'loss_function': criterion,  # The loss function (criterion) used during training.\n",
        "                      'performances': performances,  # Performances of the model\n",
        "                      'lr_scheduler_state_dict': None,  # If using a scheduler\n",
        "                      'hyperparameters': {\n",
        "                          'batch_size': batch_size,\n",
        "                          'learning_rate': learning_rate\n",
        "                      },\n",
        "                      'random_seed': random_seed,\n",
        "                      'library_versions': {\n",
        "                          'torch': torch.__version__,\n",
        "                          'numpy': np.__version__\n",
        "                      }\n",
        "                      }\n",
        "        checkpoint_dir = os.path.join('/content/drive/MyDrive/indeep/checkpoints', f'checkpoint_{model_name}_{num_epochs}_epoch.pth')\n",
        "        print(f'\\nsaving checkpoint in {checkpoint_dir}\\n')\n",
        "        torch.save(checkpoint_dict, checkpoint_dir)\n",
        "\n",
        "    return performances, model"
      ],
      "metadata": {
        "id": "c0AickSkyJzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model):\n",
        "    \"\"\"Function to compute the model performance on the test set\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    confusion_matrix = np.zeros((len(class_names), len(class_names)))\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch_data in enumerate(dataloader['test']):\n",
        "            batch = {'pixel_values': batch_data[0], 'label': batch_data[1]}\n",
        "            images, labels = batch['pixel_values'].squeeze(1).to(device), batch['label'].to(device)\n",
        "            outputs = model(images).logits\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            for i, l in enumerate(labels):\n",
        "                all_labels.append(labels[i].item())\n",
        "                all_predictions.append(predicted[i].item())\n",
        "\n",
        "                confusion_matrix[int(labels[i]), int(predicted[i])] += 1\n",
        "\n",
        "        results = {'label': all_labels, 'predictions': all_predictions}\n",
        "        results_df = pd.DataFrame(results)\n",
        "\n",
        "        performance_test = calculate_performance(confusion_matrix, class_names, model_name)\n",
        "\n",
        "        plot_confusion_matrix(performance_test, confusion_matrix, class_names)\n",
        "\n",
        "        return"
      ],
      "metadata": {
        "id": "ig63GlPRyd5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can actually start the training, using all the functions and classes defined above"
      ],
      "metadata": {
        "id": "XxM9oJt2JiXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset and creating the dataloader\n",
        "dataloader = data_loading(dataset=dataset_name)"
      ],
      "metadata": {
        "id": "ZQZguhMpykAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "model = model_creation(num_classes=len(class_names))"
      ],
      "metadata": {
        "id": "XnlTgQVnyiQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Starting the training\n",
        "model.to(device)\n",
        "performances, model = training(dataloader, model)"
      ],
      "metadata": {
        "id": "hwlKRXREylbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the training is concluded we can assess the actual performance on a test set. If you have just concluded the training you can skip the loading of the checkpoint.\n",
        "Otherwise, if you want only to test the model, build the dataloader, build the model again, define the function needed, load the checkpoint, and go to the testing!"
      ],
      "metadata": {
        "id": "R7KxjGCZKhGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = f'checkpoint_{model_name}_{num_epochs}_epoch.pth'\n",
        "checkpoint_dir = os.path.join('/content/drive/MyDrive/indeep/checkpoints', filename)\n",
        "checkpoint = torch.load(checkpoint_dir, map_location=torch.device(device))"
      ],
      "metadata": {
        "id": "ebrau63PKg0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "test(dataloader, model)"
      ],
      "metadata": {
        "id": "jivQdihHyo_T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}